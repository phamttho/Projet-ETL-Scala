# ğŸ“Š DonnÃ©es sources pour le projet final - Pipeline ETL

Ce rÃ©pertoire contient **5 datasets diffÃ©rents** pour le projet final de Programmation Fonctionnelle en Scala.

## ğŸ¯ Principe gÃ©nÃ©ral

Chaque Ã©tudiant choisit **1 dataset** parmi les 5 proposÃ©s et doit crÃ©er **de zÃ©ro** un pipeline ETL complet :
- **Extract** : Parser les fichiers JSON avec Circe
- **Transform** : Calculer des statistiques avec les HOFs et monades
- **Load** : Exporter les rÃ©sultats en JSON et texte

**Important** : Vous devrez analyser vous-mÃªme les fichiers JSON fournis et crÃ©er vos propres case classes. Les spÃ©cifications ne contiennent que la structure des outputs attendus, pas les valeurs finales.

## ğŸ“š PrÃ©requis

Ce projet mobilise **tous les concepts vus en cours** :
- âœ… **ImmutabilitÃ©** : val, case classes
- âœ… **Fonctions d'ordre supÃ©rieur** : map, filter, flatMap, fold, groupBy, sortBy, etc.
- âœ… **Monades** : Option[T], Try[T], Either[L, R]
- âœ… **For-comprehension** : Composition de monades
- âœ… **Parsing JSON** : Circe (io.circe)
- âœ… **File I/O** : Lecture et Ã©criture de fichiers

Si l'un de ces concepts n'est pas clair, **rÃ©visez les sÃ©ances prÃ©cÃ©dentes avant de commencer !**

## ğŸ“ Structure

Chaque dataset contient :
- `SPECIFICATIONS.md` : Cahier des charges dÃ©taillÃ© avec la structure des outputs attendus
- `data_clean.json` : 100 entrÃ©es parfaitement formatÃ©es (pour dÃ©buter)
- `data_dirty.json` : 500 entrÃ©es avec erreurs (champs manquants, valeurs nulles, doublons)
- `data_large.json` : 10 000+ entrÃ©es (test de performance)

## ğŸš€ Comment dÃ©marrer ?

### Ã‰tape 1 : Choisir votre dataset
Parcourez les 5 dossiers et lisez les `SPECIFICATIONS.md`. Choisissez le sujet qui vous intÃ©resse le plus !

### Ã‰tape 2 : Analyser les donnÃ©es
Ouvrez `data_clean.json` de votre dataset choisi et analysez la structure JSON. Vous devrez crÃ©er une ou plusieurs case classes qui correspondent Ã  cette structure.

### Ã‰tape 3 : CrÃ©er votre projet SBT
```bash
# CrÃ©ez un nouveau projet Scala
mkdir mon-projet-etl
cd mon-projet-etl
```

CrÃ©ez `build.sbt` avec les dÃ©pendances nÃ©cessaires (voir section Technologies).

### Ã‰tape 4 : Copier les fichiers de donnÃ©es
Copiez les 3 fichiers JSON de votre dataset choisi dans votre projet (par exemple dans `data/`).

### Ã‰tape 5 : Commencer le dÃ©veloppement
1. CrÃ©ez vos case classes en analysant le JSON
2. ImplÃ©mentez le parsing avec Circe
3. Testez d'abord avec `data_clean.json`
4. Ajoutez la gestion d'erreurs pour `data_dirty.json`
5. ImplÃ©mentez les transformations demandÃ©es
6. Exportez les rÃ©sultats
7. Testez les performances avec `data_large.json`

## ğŸŒ Datasets disponibles

### 1. Countries - Pays du monde
**Dossier** : `1-countries/`  
**ThÃ©matique** : DonnÃ©es gÃ©ographiques et dÃ©mographiques  
**Exemples de stats** : Top pays par population, PIB moyen par continent, langues officielles

### 2. Football Players - Joueurs de football
**Dossier** : `2-football-players/`  
**ThÃ©matique** : Statistiques de joueurs professionnels  
**Exemples de stats** : Top buteurs, moyenne d'Ã¢ge par poste, salaires par ligue

### 3. Movies - Films et sÃ©ries
**Dossier** : `3-movies/`  
**ThÃ©matique** : Base de donnÃ©es type IMDb  
**Exemples de stats** : Films les mieux notÃ©s, acteurs prolifiques, genres populaires

### 4. Climate Events - Ã‰vÃ©nements climatiques
**Dossier** : `4-climate-events/`  
**ThÃ©matique** : Catastrophes naturelles et donnÃ©es mÃ©tÃ©o  
**Exemples de stats** : Ã‰vÃ©nements par type, coÃ»ts des dÃ©gÃ¢ts, zones Ã  risque

### 5. League of Legends Champions
**Dossier** : `5-lol-champions/`  
**ThÃ©matique** : Champions et statistiques de gameplay  
**Exemples de stats** : Win rate par rÃ´le, champions les plus bannis, pick rate

## ğŸ“ Consignes gÃ©nÃ©rales

### Partie 1 : Parsing et validation (40%)
- **Analyser** les fichiers JSON fournis et crÃ©er vos propres case classes
- **Parser** les 3 fichiers JSON avec Circe (`io.circe.parser._`)
- **Valider** les donnÃ©es selon les critÃ¨res du `SPECIFICATIONS.md`
- **GÃ©rer** les erreurs avec `Option`/`Try`/`Either` et for-comprehension
- **Logger** le nombre d'entrÃ©es lues, valides, erreurs et doublons supprimÃ©s

### Partie 2 : Transformations (40%)
- **Calculer** toutes les statistiques obligatoires demandÃ©es dans `SPECIFICATIONS.md`
- **Utiliser** les HOFs : `map`, `filter`, `flatMap`, `groupBy`, `sortBy`, `fold`, etc.
- **Composer** les opÃ©rations avec les for-comprehension quand appropriÃ©
- Les statistiques bonus sont optionnelles mais valorisÃ©es

### Partie 3 : Export (20%)
- **GÃ©nÃ©rer** `results.json` avec les rÃ©sultats (structure indiquÃ©e dans les specs)
- **GÃ©nÃ©rer** `report.txt` avec un rapport lisible et bien formatÃ©
- **Mesurer** et afficher le temps de traitement (code fourni dans les specs)
- Les fichiers de sortie doivent Ãªtre dans un dossier `output/`

## ğŸ“¦ Technologies recommandÃ©es

```scala
// build.sbt
libraryDependencies ++= Seq(
  "io.circe" %% "circe-core" % "0.14.6",
  "io.circe" %% "circe-generic" % "0.14.6",
  "io.circe" %% "circe-parser" % "0.14.6",
  "org.scalameta" %% "munit" % "0.7.29" % Test
)
```

## â±ï¸ DurÃ©e

- **SÃ©ance 1** (3h30) : Parsing, validation, premiÃ¨res transformations
- **SÃ©ance 2** (3h30) : Transformations avancÃ©es, export, optimisation

## ğŸ“ Rendu

**Deadline** : 1 semaine aprÃ¨s la derniÃ¨re sÃ©ance  
**Format** : Archive ZIP nommÃ©e `nom_prenom_dataset.zip` (ex: `dupont_jean_countries.zip`)

**Contenu de l'archive** :
```
nom_prenom_dataset/
â”œâ”€â”€ build.sbt
â”œâ”€â”€ project/
â”‚   â””â”€â”€ build.properties
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â””â”€â”€ scala/
â”‚           â””â”€â”€ [votre code]
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data_clean.json
â”‚   â”œâ”€â”€ data_dirty.json
â”‚   â””â”€â”€ data_large.json
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ results.json        (gÃ©nÃ©rÃ© par votre code)
â”‚   â””â”€â”€ report.txt          (gÃ©nÃ©rÃ© par votre code)
â””â”€â”€ README.md               (vos instructions)
```

**Votre README.md doit contenir** :
- Le dataset choisi
- Comment compiler et exÃ©cuter le projet
- Explication des choix techniques (case classes, gestion d'erreurs)
- Temps d'exÃ©cution obtenu sur `data_large.json`
- DifficultÃ©s rencontrÃ©es et solutions apportÃ©es

## ğŸ¯ CritÃ¨res d'Ã©valuation

| CritÃ¨re | Points |
|---------|--------|
| Structure du code & case classes | 3 pts |
| Gestion des erreurs (Option/Try/Either) | 3 pts |
| HOFs et transformations | 3 pts |
| Parsing JSON (Circe) | 3 pts |
| RÃ©sultats corrects | 3 pts |
| Gestion du fichier bruitÃ© | 1 pt |
| Performance (fichier large) | 1 pt |
| Documentation (README + commentaires) | 3 pts |
| **Total** | **20 pts** |

**Bonus** (+2 pts max) :
- Tests unitaires avec MUnit (+1pt)
- Statistiques supplÃ©mentaires crÃ©atives (+0.5pt)
- Gestion avancÃ©e des erreurs (+0.5pt)

## ğŸ’¡ Conseils pratiques

### Pour le parsing
1. **Commencez par `data_clean.json`** : Assurez-vous que votre parsing fonctionne parfaitement
2. **Utilisez `io.circe.generic.auto._`** : Import automatique des encoders/decoders
3. **Testez avec une seule entrÃ©e d'abord** : Avant de parser tout le fichier
4. **N'oubliez pas les `Option`** : Pour les champs qui peuvent Ãªtre manquants

### Pour la validation
1. **CrÃ©ez des fonctions de validation** : RÃ©utilisables et testables
2. **Utilisez for-comprehension** : Pour composer les validations avec `Either`
3. **Loggez toutes les erreurs** : Comptez parsing errors, duplicates, invalid data

### Pour les transformations
1. **Une transformation = une fonction** : Code modulaire et testable
2. **VÃ©rifiez les cas limites** : Divisions par zÃ©ro, listes vides, etc.
3. **Utilisez les HOFs du cours** : `groupBy`, `sortBy`, `maxBy`, `fold`, etc.
4. **Testez chaque statistique individuellement** : Avant de tout exporter

### Pour l'optimisation
1. **`data_large.json` en dernier** : Optimisez seulement si nÃ©cessaire
2. **Ã‰vitez les transformations multiples** : Combinez les opÃ©rations quand possible
3. **L'objectif est < 10 secondes** : Sur un ordinateur moderne

### Pour la documentation
1. **Commentez les parties complexes** : Surtout les for-comprehension
2. **README clair** : Instructions pour compiler et exÃ©cuter
3. **Expliquez vos choix** : Structure des case classes, gestion d'erreurs


**Bon courage !** ğŸ“ N'hÃ©sitez pas Ã  poser des questions pendant les sÃ©ances de projet !

